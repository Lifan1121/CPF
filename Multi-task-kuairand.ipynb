{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kwECuOJQOkVB",
    "outputId": "669332e7-3091-4fdf-e7cf-0a851a80143a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 01:25:42.469868: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:25:42.470019: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:25:42.470081: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:25:42.470172: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:25:42.470230: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:25:42.470280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 5092 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-10-23 01:25:42.470624: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:25:42.470771: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:25:42.470856: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:25:42.470931: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:25:42.470990: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:25:42.471037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5092 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model # type: ignore\n",
    "\n",
    "print(tf.test.is_gpu_available())\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "def seed_tensorflow(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_train_label\n",
    "# short_play\n",
    "# effective_play\n",
    "# long_play\n",
    "# complete_play\n",
    "\n",
    "# base_model = \"./model/kuairand_backbone/mlp_{}.h5\".format(select_label)\n",
    "CPF_model = \"./model/kuairand_CPF/mlp_{}.h5\".format('CPF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "HR60fa-TOkVD"
   },
   "outputs": [],
   "source": [
    "para = {'data_path':'./kuai_input/',\n",
    "        'embedding_dim':64,\n",
    "        'seed':0,\n",
    "        'lr':1e-5,\n",
    "        'batch_size':512,\n",
    "        'epochs':64,\n",
    "        'verbose':1,\n",
    "        'callback':{\n",
    "                     'monitor':'val_auc',\n",
    "                     'patience':10,\n",
    "                     'CPF_model':CPF_model\n",
    "                     },\n",
    "        'mlp_dims':[256,128,64],\n",
    "        'mlp_act':'relu',\n",
    "        'mlp_dps':[.5,.5,.5],\n",
    "       }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "pTEhArDxOkVE"
   },
   "outputs": [],
   "source": [
    "action = pd.read_csv(para['data_path']+\"action.csv\")\n",
    "feed_emb = np.load(para['data_path']+\"embeddings.npy\")\n",
    "action = action[['user_id','video_id','duration_level','tab','user_active_degree','author_id','music_id',\n",
    "                 'short_play', 'binary_train_label', 'effective_play',\n",
    "                 'long_play', 'complete_play','date']]\n",
    "categories_to_keep = ['full_active', 'high_active', 'middle_active','low_active']\n",
    "\n",
    "action = action[action['user_active_degree'].isin(categories_to_keep)]\n",
    "\n",
    "category_mapping = {\n",
    "    'low_active': 0,\n",
    "    'middle_active': 1,\n",
    "    'high_active': 2,\n",
    "    'full_active': 3\n",
    "}\n",
    "\n",
    "action['user_active_degree_encoded'] = action['user_active_degree'].map(category_mapping)\n",
    "action['music_id_encoded'], _ = pd.factorize(action['music_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#action = action.sort_values(by=['date'])\n",
    "train= action.groupby('user_id').apply(lambda x: x[:int(len(x)*0.6)]).reset_index(drop=True)\n",
    "valid= action.groupby('user_id').apply(lambda x: x[int(len(x)*0.6):int(len(x)*0.8)]).reset_index(drop=True)\n",
    "test= action.groupby('user_id').apply(lambda x: x[int(len(x)*0.8):]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "uTeoDcHyOkVH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 02:45:44.886642: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 02:45:44.887005: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 02:45:44.887095: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 02:45:44.887250: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 02:45:44.887355: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 02:45:44.887429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5092 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "seed_tensorflow(seed=para['seed'])\n",
    "\"\"\"\n",
    "    uid_lay = get_layer((1,),'uid',d1 = max(action['user_id'])+1,d2 = para['embedding_dim'],trainable=True)\n",
    "    videoid_lay = get_layer((1,),'video_id',d1 = max(action['video_id'])+1,d2 = int(para['embedding_dim']),trainable=True)\n",
    "    duration_lay = get_layer((1,),'duration_id',d1 = max(action['duration_level'])+1,d2 = int(para['embedding_dim']),trainable=True)\n",
    "    tab_lay = get_layer((1,),'tab',d1 = max(action['tab'])+1,d2 = int(para['embedding_dim']),trainable=True)\n",
    "    user_active_degree_encoded = get_layer((1,),'user_active_degree_encoded',d1 = max(action['user_active_degree_encoded'])+1,d2 = int(para['embedding_dim']),trainable=True)\n",
    "    author_lay = get_layer((1,),'author_id',d1 = max(action['author_id'])+1,d2 = int(para['embedding_dim']),trainable=True)\n",
    "    music_lay = get_layer((1,),'music_id_encoded',d1 = max(action['music_id_encoded'])+1,d2 = int(para['embedding_dim']),trainable=True)\n",
    "\"\"\"\n",
    "\n",
    "features = ['user_id','video_id','duration_level','tab','user_active_degree_encoded','author_id','music_id_encoded','video_id','short_play','binary_train_label','effective_play'\n",
    "            ,'long_play','complete_play']\n",
    "\n",
    "# # short_play binary_train_label effective_play long_play complete_play\n",
    "def get_input(df,is_test=False):\n",
    "    X = []\n",
    "    for f in features:\n",
    "        X.append(df[f].values.reshape(-1,1))\n",
    "    labels = ['short_play', 'binary_train_label', 'effective_play', 'long_play', 'complete_play']\n",
    "    \n",
    "    # Create a list of label arrays, one for each task\n",
    "    y = [df[label].values.reshape(-1, 1) for label in labels]\n",
    "    return X,y\n",
    "\n",
    "X_train,y_train = get_input(train,is_test=False)\n",
    "X_valid,y_valid = get_input(valid,is_test=False)\n",
    "X_test,y_test = get_input(test,is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "lqSon1J4OkVI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 01:26:01.216907: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:26:01.217084: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:26:01.217150: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:26:01.217247: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:26:01.217309: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:26:01.217362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5092 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "seed_tensorflow(seed=para['seed'])\n",
    "\n",
    "def get_layer(shape,name,dtype='int32',d1=None,d2=None,pretrain=None,trainable=False):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=shape, name=name+'_input', dtype=dtype))\n",
    "    if d1 is None:\n",
    "        d1 = pretrain.shape[0]\n",
    "        d2 = pretrain.shape[1]\n",
    "    model.add(tf.keras.layers.Embedding(input_dim=int(d1),\n",
    "                       output_dim=int(d2),\n",
    "                       weights=[pretrain] if pretrain is not None else None,\n",
    "                       trainable=trainable,\n",
    "                       name=name+'_embedding'))\n",
    "    return model\n",
    "#'user_id','video_id','duration_level','tab','user_active_degree','author_id','music_id'\n",
    "def mlp_bias(TRAIN):\n",
    "    uid_lay = get_layer((1,),'uid',d1 = max(action['user_id'])+1,d2 = para['embedding_dim'],trainable=TRAIN)\n",
    "    videoid_lay = get_layer((1,),'video_id',d1 = max(action['video_id'])+1,d2 = int(para['embedding_dim']),trainable=TRAIN)\n",
    "    duration_lay = get_layer((1,),'duration_id',d1 = max(action['duration_level'])+1,d2 = int(para['embedding_dim']),trainable=TRAIN)\n",
    "    tab_lay = get_layer((1,),'tab',d1 = max(action['tab'])+1,d2 = int(para['embedding_dim']),trainable=TRAIN)\n",
    "    user_active_degree_encoded = get_layer((1,),'user_active_degree_encoded',d1 = max(action['user_active_degree_encoded'])+1,d2 = int(para['embedding_dim']),trainable=TRAIN)\n",
    "    author_lay = get_layer((1,),'author_id',d1 = max(action['author_id'])+1,d2 = int(para['embedding_dim']),trainable=TRAIN)\n",
    "    music_lay = get_layer((1,),'music_id_encoded',d1 = max(action['music_id_encoded'])+1,d2 = int(para['embedding_dim']),trainable=TRAIN)\n",
    "    \n",
    "    pre_lay = get_layer((1,),'pretrain',pretrain = feed_emb,trainable=False)\n",
    "    label_input_SP = tf.keras.layers.Input(shape=(1,), name='SP')\n",
    "    label_input_BP = tf.keras.layers.Input(shape=(1,), name='BP')\n",
    "    label_input_EP = tf.keras.layers.Input(shape=(1,), name='EP')\n",
    "    label_input_LP = tf.keras.layers.Input(shape=(1,), name='LP')\n",
    "    label_input_CP = tf.keras.layers.Input(shape=(1,), name='CP')\n",
    "\n",
    "    Lay_bi =[uid_lay,videoid_lay,duration_lay,tab_lay,user_active_degree_encoded,author_lay,music_lay,pre_lay]\n",
    "\n",
    "\n",
    "    lay_bi_outs = []\n",
    "    for l in Lay_bi:\n",
    "        lay_bi_outs += l.outputs\n",
    "\n",
    "    vec = tf.keras.layers.concatenate(lay_bi_outs,axis=-1)\n",
    "    vec = tf.squeeze(vec,axis=1)\n",
    "    \n",
    "    #vec = tf.keras.layers.BatchNormalization()(vec)\n",
    "\n",
    "    vec = tf.keras.layers.Dense(256,\n",
    "                                    activation = 'relu',\n",
    "                                    name='mlp_dense0')(vec)\n",
    "\n",
    "    vec = tf.keras.layers.Dropout(0.5)(vec)\n",
    "\n",
    "    vec = tf.keras.layers.Dense(128,\n",
    "                                    activation = 'relu',\n",
    "                                    name='mlp_dense1')(vec)\n",
    "\n",
    "    vec = tf.keras.layers.Dropout(0.5)(vec)\n",
    "\n",
    "    instance = tf.keras.layers.Dense(64,\n",
    "                                    activation = 'relu',\n",
    "                                    name='instance')(vec)\n",
    "    #instance = tf.keras.layers.Dropout(0.5)(vec)\n",
    "\n",
    "    #instance = tf.keras.layers.BatchNormalization(name='instance')(vec)\n",
    "\n",
    "    model_inputs = []\n",
    "    for l in Lay_bi:\n",
    "        model_inputs += l.inputs\n",
    "    model_inputs += [label_input_SP]\n",
    "    model_inputs += [label_input_BP]\n",
    "    model_inputs += [label_input_EP]\n",
    "    model_inputs += [label_input_LP]\n",
    "    model_inputs += [label_input_CP]\n",
    "    model = tf.keras.Model(inputs=model_inputs,outputs=[instance])\n",
    "\n",
    "    return model # 返回一个模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JcsOlGqbOkVI",
    "outputId": "aca5082e-591a-4040-c2ad-ba7b28b90219"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 01:26:01.223133: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:26:01.223297: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:26:01.223360: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:26:01.223451: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:26:01.223608: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 01:26:01.223658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5092 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " uid_input (InputLayer)      [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " video_id_input (InputLayer  [(None, 1)]                  0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " duration_id_input (InputLa  [(None, 1)]                  0         []                            \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " tab_input (InputLayer)      [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " user_active_degree_encoded  [(None, 1)]                  0         []                            \n",
      " _input (InputLayer)                                                                              \n",
      "                                                                                                  \n",
      " author_id_input (InputLaye  [(None, 1)]                  0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " music_id_encoded_input (In  [(None, 1)]                  0         []                            \n",
      " putLayer)                                                                                        \n",
      "                                                                                                  \n",
      " pretrain_input (InputLayer  [(None, 1)]                  0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " uid_embedding (Embedding)   (None, 1, 64)                1631488   ['uid_input[0][0]']           \n",
      "                                                                                                  \n",
      " video_id_embedding (Embedd  (None, 1, 64)                448960    ['video_id_input[0][0]']      \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " duration_id_embedding (Emb  (None, 1, 64)                320       ['duration_id_input[0][0]']   \n",
      " edding)                                                                                          \n",
      "                                                                                                  \n",
      " tab_embedding (Embedding)   (None, 1, 64)                960       ['tab_input[0][0]']           \n",
      "                                                                                                  \n",
      " user_active_degree_encoded  (None, 1, 64)                256       ['user_active_degree_encoded_i\n",
      " _embedding (Embedding)                                             nput[0][0]']                  \n",
      "                                                                                                  \n",
      " author_id_embedding (Embed  (None, 1, 64)                385984    ['author_id_input[0][0]']     \n",
      " ding)                                                                                            \n",
      "                                                                                                  \n",
      " music_id_encoded_embedding  (None, 1, 64)                439744    ['music_id_encoded_input[0][0]\n",
      "  (Embedding)                                                       ']                            \n",
      "                                                                                                  \n",
      " pretrain_embedding (Embedd  (None, 1, 64)                448960    ['pretrain_input[0][0]']      \n",
      " ing)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 1, 512)               0         ['uid_embedding[0][0]',       \n",
      " )                                                                   'video_id_embedding[0][0]',  \n",
      "                                                                     'duration_id_embedding[0][0]'\n",
      "                                                                    , 'tab_embedding[0][0]',      \n",
      "                                                                     'user_active_degree_encoded_e\n",
      "                                                                    mbedding[0][0]',              \n",
      "                                                                     'author_id_embedding[0][0]', \n",
      "                                                                     'music_id_encoded_embedding[0\n",
      "                                                                    ][0]',                        \n",
      "                                                                     'pretrain_embedding[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_6 (TF  (None, 512)                  0         ['concatenate_6[0][0]']       \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " mlp_dense0 (Dense)          (None, 256)                  131328    ['tf.compat.v1.squeeze_6[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)        (None, 256)                  0         ['mlp_dense0[0][0]']          \n",
      "                                                                                                  \n",
      " mlp_dense1 (Dense)          (None, 128)                  32896     ['dropout_12[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)        (None, 128)                  0         ['mlp_dense1[0][0]']          \n",
      "                                                                                                  \n",
      " instance (Dense)            (None, 64)                   8256      ['dropout_13[0][0]']          \n",
      "                                                                                                  \n",
      " SP (InputLayer)             [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " BP (InputLayer)             [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " EP (InputLayer)             [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " LP (InputLayer)             [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " CP (InputLayer)             [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " dense_58 (Dense)            (None, 1)                    65        ['instance[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3529217 (13.46 MB)\n",
      "Trainable params: 3080257 (11.75 MB)\n",
      "Non-trainable params: 448960 (1.71 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "seed_tensorflow(seed=para['seed'])\n",
    "base_model_backbone = mlp_bias(True)\n",
    "\n",
    "\n",
    "# n*64\n",
    "vec = base_model_backbone.outputs[0] # instance     dim=64\n",
    "final_output = tf.keras.layers.Dense(1,\"sigmoid\")(vec)\n",
    "\n",
    "# Create a model that includes the routed output\n",
    "model = Model(inputs=base_model_backbone.inputs, outputs=final_output)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_tensors = [tf.random.normal([10, 64], mean=0.0, stddev=1.0, dtype=tf.float32) for _ in range(5)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qhzp8DSXOkVK"
   },
   "source": [
    "# prototype generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "Ee8CBS5UOkVM"
   },
   "outputs": [],
   "source": [
    "class Prototypes(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 k ,\n",
    "                 beta1=0.0,\n",
    "                 beta2=0.0,\n",
    "                 beta3=0.0,\n",
    "                 init_prototypes = None,\n",
    "                 **kwargs):\n",
    "        super(Prototypes, self).__init__(**kwargs)\n",
    "        self.k = k\n",
    "        self.beta1, self.beta2, self.beta3 = beta1, beta2, beta3\n",
    "        # y_train[0]\n",
    "        self.init_prototypes = init_prototypes\n",
    "        self.binary_classifiers = []\n",
    "        # \n",
    "        for _ in range(5):\n",
    "            mlp = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "            ])\n",
    "            mlp.build((None, 64))\n",
    "            self.binary_classifiers.append(mlp)\n",
    "            \n",
    "    # define prototype\n",
    "    def build(self, input_shape):\n",
    "        self.prototypes = self.add_weight(\n",
    "            name='prototypes',\n",
    "            shape=(1, self.k, 64),\n",
    "            initializer=tf.keras.initializers.Constant(self.init_prototypes[tf.newaxis, :, :]),\n",
    "            trainable=True\n",
    "        )\n",
    "        super(Prototypes, self).build(input_shape)\n",
    "\n",
    "    \n",
    "    def orthogonality_loss(self,prototypes, k):\n",
    "        # 确保传入的 k 是偶数\n",
    "        assert k % 2 == 0, \"k must be even.\"\n",
    "        D = k // 2\n",
    "\n",
    "        prototypes = tf.reshape(prototypes, [k, 64])\n",
    "        prototypes = tf.nn.l2_normalize(prototypes, axis=1)\n",
    "\n",
    "        cosine_similarity_matrix = tf.matmul(prototypes, prototypes, transpose_b=True)\n",
    "\n",
    "        upper_triangular_part = tf.linalg.band_part(cosine_similarity_matrix, 0, -1)\n",
    "        upper_triangular_part -= tf.linalg.band_part(cosine_similarity_matrix, 0, 0)  # 去掉对角线\n",
    "\n",
    "        loss = tf.reduce_sum(tf.square(upper_triangular_part))\n",
    "        normalization_factor = D * (2 * D - 1)\n",
    "        loss /= normalization_factor\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def contrastive_loss(self, vec, labels, duration):\n",
    "        # Normalize the vectors\n",
    "        vec_norm = tf.nn.l2_normalize(vec, axis=1)\n",
    "        #print(\"vec_norm\",vec_norm)\n",
    "        sim_matrix = tf.matmul(vec_norm, vec_norm, transpose_b=True)\n",
    "        #print(\"sim_matrix\",sim_matrix)\n",
    "        # Create masks\n",
    "        label_eq = tf.equal(labels, tf.transpose(labels))\n",
    "        #print(\"label_eq\",label_eq)\n",
    "        duration_eq = tf.equal(duration, tf.transpose(duration))\n",
    "        #print(\"duration_eq\",duration_eq)\n",
    "        mask = tf.logical_and(label_eq, duration_eq)\n",
    "        mask = tf.cast(mask, dtype=tf.float32)\n",
    "        #print(\"mask\",mask)\n",
    "\n",
    "        # Compute the softmax denominator\n",
    "        exp_sim = tf.exp(sim_matrix)\n",
    "        total_sum = tf.reduce_sum(exp_sim)\n",
    "        #print(\"total_sum\",total_sum)\n",
    "        normal_sim = exp_sim / total_sum\n",
    "        #print(\"normal_sim\",normal_sim)\n",
    "\n",
    "        log_normal_sim = tf.math.log(normal_sim)\n",
    "        weighted_log_prob = mask * log_normal_sim\n",
    "\n",
    "        num_ones = tf.reduce_sum(mask)\n",
    "\n",
    "        loss = -tf.reduce_sum(weighted_log_prob)\n",
    "        return loss/num_ones\n",
    "\n",
    "    def assign_loss(self,output, vec):\n",
    "\n",
    "\n",
    "        output_norm = tf.nn.l2_normalize(output, axis=1)\n",
    "        vec_norm = tf.nn.l2_normalize(vec, axis=1)\n",
    "\n",
    "        cosine_similarity = tf.reduce_sum(tf.multiply(output_norm, vec_norm), axis=1)\n",
    "        loss = 1 - tf.reduce_mean(cosine_similarity)\n",
    "        return loss\n",
    "    def get_alpha(self,n_batch,duration_one_hot_expanded,alpha_product):\n",
    "        \"\"\"\n",
    "        alpha_product : (n,10,1)\n",
    "        duration_one_hot_expanded: (n,5,1)\n",
    "        \"\"\"\n",
    "        expanded_alpha = tf.reshape(alpha_product, [n_batch, 5, 2, 1])\n",
    "        masked = expanded_alpha * tf.cast(duration_one_hot_expanded, tf.float32)[:, :, :, tf.newaxis]\n",
    "        # n,2,1\n",
    "        alpha_para = tf.reduce_sum(masked, axis=1)\n",
    "        alpha_neg = alpha_para[:, 0, :]  # 第一个元素，保留最后一个轴\n",
    "        alpha_pos = alpha_para[:, 1, :]  # 第二个元素，保留最后一个轴\n",
    "        return alpha_neg,alpha_pos\n",
    "    def mse_loss(self,vec,label):\n",
    "        vec = tf.convert_to_tensor(vec, dtype=tf.float32)\n",
    "\n",
    "        label = tf.convert_to_tensor(label, dtype=tf.float32)\n",
    "\n",
    "        squeezed_label = tf.squeeze(label)\n",
    "\n",
    "        #tf.print(label, summarize=-1)\n",
    "        positive_indices = tf.where(squeezed_label == 1)\n",
    "        negative_indices = tf.where(squeezed_label == 0)\n",
    "\n",
    "        positive_samples = tf.gather(vec, positive_indices)\n",
    "        negative_samples = tf.gather(vec, negative_indices)\n",
    "        positive_samples = tf.squeeze(positive_samples,axis=1)\n",
    "        negative_samples = tf.squeeze(negative_samples,axis=1)\n",
    "        positive_loss = tf.reduce_mean(tf.square(positive_samples - self.pos_mean_prototype))\n",
    "        negative_loss = tf.reduce_mean(tf.square(negative_samples - self.neg_mean_prototype))\n",
    "\n",
    "        total_loss = positive_loss * 0.7 + negative_loss * 0.3\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def binary_loss(self,alpha, labels):\n",
    "        bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "        loss = bce(labels, alpha)\n",
    "        return loss     \n",
    "    \n",
    "    def create_mask(self,duration, batch_size, num_classes=40, bucket_size=8):\n",
    "        start_indices = duration * bucket_size\n",
    "        masks = []\n",
    "        for i in range(batch_size):\n",
    "            mask = tf.concat([\n",
    "                tf.zeros((start_indices[i, 0], 1), dtype=tf.float32),\n",
    "                tf.ones((bucket_size, 1), dtype=tf.float32),\n",
    "                tf.zeros((num_classes - start_indices[i, 0] - bucket_size, 1), dtype=tf.float32)\n",
    "            ], axis=0)\n",
    "            masks.append(mask)\n",
    "        return tf.stack(masks)\n",
    "    def binary_crossentropy_manual(self, y_true, y_pred,para):\n",
    "        y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "\n",
    "        # 防止 log(0) 的情况发生\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "        loss = -y_true * tf.math.log(y_pred) - (1 - y_true) * tf.math.log(1 - y_pred)\n",
    "\n",
    "        weights = tf.where(y_true == 1, para, 1.0)\n",
    "        weighted_loss = loss * weights\n",
    "\n",
    "        positive_loss = tf.boolean_mask(weighted_loss, y_true == 1)\n",
    "        negative_loss = tf.boolean_mask(weighted_loss, y_true == 0)\n",
    "        #total_positive_loss = tf.reduce_sum(positive_loss)\n",
    "        #total_negative_loss = tf.reduce_sum(negative_loss)\n",
    "\n",
    "        return tf.reduce_mean(weighted_loss)\n",
    "    def prototype_loss(self,prototypes_output):\n",
    "        bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "        labels = tf.constant([[0], [1], [0], [1], [0], [1], [0], [1], [0], [1]], dtype=tf.float32)\n",
    "        loss = bce(labels, prototypes_output)\n",
    "        return loss\n",
    "    \n",
    "    def call(self, x, training=None):\n",
    "\n",
    "        vec,duration,label = x\n",
    "        a = tf.expand_dims(vec, -2)\n",
    "\n",
    "        b = self.prototypes\n",
    "        n_batch = tf.shape(vec)[0]\n",
    "\n",
    "        dot_product = tf.multiply(a, b)\n",
    "\n",
    "        norm_a = tf.norm(a, axis=-1, keepdims=True)  # 保持维度，使得维度是 [batch_size, 1, 1]\n",
    "\n",
    "        norm_b = tf.norm(b, axis=-1, keepdims=True)  # 保持维度，使得维度是 [1, k, 1]\n",
    "\n",
    "        # (batch_size, k,1)\n",
    "        sum_product = tf.reduce_sum(dot_product, axis=-1, keepdims=True)\n",
    "        cos_similarity = sum_product / (norm_a * norm_b)\n",
    "        \n",
    "        #tf.print(cos_similarity.shape)\n",
    "        \"\"\"\n",
    "        tf.print(vec,summarize=-1)\n",
    "        tf.print(self.prototypes,summarize=-1)\n",
    "        tf.print(\"Input duration\")\n",
    "        tf.print(duration.shape)\n",
    "        tf.print(\"Input label\")\n",
    "        tf.print(label.shape)\n",
    "        #tf.print(vec)\n",
    "        tf.print(duration, summarize=-1)\n",
    "        tf.print(label, summarize=-1)\n",
    "\n",
    "        tf.print(dot_product.shape)\n",
    "        tf.print(dot_product)\n",
    "\n",
    "        tf.print(sum_product.shape)\n",
    "        tf.print(sum_product,summarize=-1)\n",
    "\n",
    "        tf.print(norm_a.shape)\n",
    "        tf.print(norm_a)\n",
    "\n",
    "        tf.print(norm_b.shape)\n",
    "        tf.print(norm_b)\n",
    "\n",
    "        tf.print(cos_similarity, summarize=-1)\n",
    "        \"\"\"\n",
    "        # （batch_size, k//2, 2, 1)\n",
    "        reshaped_sum_product = tf.reshape(cos_similarity, (n_batch, self.k // 2, 2))\n",
    "\n",
    "        temperature = 0.05\n",
    "\n",
    "        scaled_logits = reshaped_sum_product / temperature\n",
    "\n",
    "        softmaxed_sum_product = tf.nn.softmax(scaled_logits, axis=2)\n",
    "\n",
    "        # (batch_size, k,1)\n",
    "        alpha_product = tf.reshape(softmaxed_sum_product, (n_batch, self.k, 1))\n",
    "        #tf.print(alpha_product,summarize=-1)\n",
    "        \"\"\"\n",
    "        tf.print(alpha_product.shape)\n",
    "        tf.print(alpha_product)\n",
    "        \"\"\"\n",
    "        #self.new = alpha_product\n",
    "        # n_batch, self.k, 64\n",
    "        # b:(1, k, 64)\n",
    "        alpha_product_expanded = tf.broadcast_to(alpha_product, [n_batch, self.k, 64])\n",
    "\n",
    "        # calculate\n",
    "        weighted_products = alpha_product_expanded * b\n",
    "\n",
    "        # add up\n",
    "        reshaped_weighted_products = tf.reshape(weighted_products, [n_batch, self.k//2, 2, 64])\n",
    "\n",
    "        # (batchsize,5,64)\n",
    "        pre_output = tf.reduce_sum(reshaped_weighted_products, axis=2)  # 对第三个维度求和\n",
    "\n",
    "        # 1 -> [0,1,0,0,0]\n",
    "        duration_one_hot = tf.one_hot(duration, depth=5)\n",
    "        duration_one_hot_expanded = tf.expand_dims(duration_one_hot, -1)\n",
    "        #(batch_size, 5, 1)\n",
    "        duration_one_hot_expanded = tf.squeeze(duration_one_hot_expanded, axis=[1])\n",
    "\n",
    "        masked_output = pre_output * duration_one_hot_expanded\n",
    "        # output (batchsize,64)\n",
    "        output = tf.reduce_sum(masked_output, axis=1)\n",
    "\n",
    "\n",
    "        # get_alpha\n",
    "        alpha_neg, alpha_pos = self.get_alpha(n_batch,duration_one_hot_expanded,alpha_product)\n",
    "        #tf.print(alpha_pos,summarize = -1)\n",
    "        #tf.print(alpha_neg,summarize = -1)\n",
    "        #tf.print(alpha_pos,summarize   =-1)\n",
    "        #tf.print(label, summarize=-1)\n",
    "        classifier_outputs = []\n",
    "\n",
    "\n",
    "        \n",
    "        for i in range(5):\n",
    "            classifier_output = self.binary_classifiers[i](tf.squeeze(self.prototypes,axis=0))\n",
    "             # (batch_size, 1, 1)#\n",
    "            #classifier_output += i\n",
    "            classifier_outputs.append(classifier_output)\n",
    "        \n",
    "        #tf.print(classifier_outputs,summarize = -1)\n",
    "        #tf.print(classifier_outputs.shape,summarize = -1)\n",
    "        indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  \n",
    "        prototype_output_elements = []\n",
    "\n",
    "        for i, idx in enumerate(indices):\n",
    "            tensor_index = i // 2  \n",
    "            element = tf.gather(classifier_outputs[tensor_index], idx, axis=0) \n",
    "            prototype_output_elements.append(element)\n",
    "\n",
    "        prototype_output = tf.concat(prototype_output_elements, axis=0)\n",
    "        prototype_output = tf.expand_dims(prototype_output,axis=1)\n",
    "        #(1,10)\n",
    "  \n",
    "        positive_indices = 2 * duration + 1\n",
    "        negative_indices = 2 * duration\n",
    "\n",
    "        positive_indices = tf.clip_by_value(positive_indices, 0, prototype_output.shape[0] - 1)\n",
    "        negative_indices = tf.clip_by_value(negative_indices, 0, prototype_output.shape[0] - 1)\n",
    "        #tf.print(alpha_pos,summarize = -1)\n",
    "        # 提取对应的 prototype_output 值\n",
    "        positive_values = tf.gather(prototype_output, positive_indices)\n",
    "        negative_values = tf.gather(prototype_output, negative_indices)\n",
    "        #positive_values = tf.squeeze(positive_values,axis=0)\n",
    "        #negative_values = tf.squeeze(negative_values,axis=0)\n",
    "        output = alpha_pos * tf.squeeze(positive_values,axis=-1) \n",
    "        assign_loss = self.assign_loss(output,vec)\n",
    "\n",
    "        binary_loss = self.binary_crossentropy_manual(label,output,1.0)\n",
    "        self.add_loss(1.0 * binary_loss)\n",
    "        # 5\n",
    "        assign = self.binary_crossentropy_manual(label,alpha_pos,1.0)\n",
    "        self.add_loss(0.05 * assign)\n",
    "\n",
    "        ortho_loss = self.orthogonality_loss(self.prototypes,self.k)\n",
    "        self.add_loss(0.05 * ortho_loss)\n",
    "\n",
    "        contrastive_loss = self.contrastive_loss(vec,label,duration)\n",
    "        self.add_loss(0.05 * contrastive_loss)\n",
    "\n",
    "        proto_loss = self.prototype_loss(prototype_output)\n",
    "        self.add_loss(0.1 * proto_loss)\n",
    "\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.output_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    def binary_crossentropy_manual(self, y_true, y_pred,para):\n",
    "        y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        loss = -y_true * tf.math.log(y_pred) - (1 - y_true) * tf.math.log(1 - y_pred)\n",
    "        weights = tf.where(y_true == 1, para, 1.0)\n",
    "        weighted_loss = loss * weights\n",
    "        return tf.reduce_mean(weighted_loss)\n",
    "    def call(self, x, training=None):\n",
    "\n",
    "        vec,duration,label = x\n",
    "        output = self.output_layer(vec)\n",
    "        binary_loss = self.binary_crossentropy_manual(label,output,1.0)\n",
    "        self.add_loss(1.0 * binary_loss)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 03:04:58.441754: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 03:04:58.442065: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 03:04:58.442207: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 03:04:58.442391: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 03:04:58.442522: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 03:04:58.442623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5092 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-10-23 03:04:58.949469: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 03:04:58.949605: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 03:04:58.949669: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 03:04:58.949761: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 03:04:58.949820: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 03:04:58.949867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5092 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "seed_tensorflow(seed=para['seed'])\n",
    "backbone = mlp_bias(True)\n",
    "#backbone.load_weights(\"./model/kuairand_CPF/mlp_effect_backbone.h5\")\n",
    "\n",
    "duration_id_input_output = backbone.get_layer(\"duration_id_input\").output\n",
    "output_names = ['SP', 'BP', 'EP', 'LP', 'CP']\n",
    "\n",
    "labels_outputs = [backbone.get_layer(name).output for name in output_names]\n",
    "flag = 1\n",
    "\"\"\"\n",
    "Multi-task\n",
    "\"\"\"\n",
    "# MLP+CPF\n",
    "if flag:\n",
    "    outputs = []  # List to hold outputs from each Prototypes layer\n",
    "\n",
    "    # Loop to create multiple Prototypes layers\n",
    "    for i in range(5):\n",
    "        prototypes_layer = Prototypes(k=10, init_prototypes=proto_tensors[i])\n",
    "\n",
    "        # Get the output from each Prototypes layer\n",
    "        output = prototypes_layer([backbone.outputs[0], duration_id_input_output, labels_outputs[i]])\n",
    "        outputs.append(output)\n",
    "else:\n",
    "    outputs = []  # List to hold outputs from each Prototypes layer\n",
    "\n",
    "    # Loop to create multiple Prototypes layers\n",
    "    for i in range(5):\n",
    "        mlp_layer = MLP()\n",
    "\n",
    "        # Get the output from each Prototypes layer\n",
    "        output = mlp_layer([backbone.outputs[0], duration_id_input_output, labels_outputs[i]])\n",
    "        outputs.append(output)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=backbone.inputs, outputs=outputs)\n",
    "\n",
    "seed_tensorflow(seed=para['seed'])\n",
    "\n",
    "adam=tf.keras.optimizers.Adam(learning_rate=para['lr'])\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=para['lr'])\n",
    "model.compile(optimizer=adam,\n",
    "              metrics=['AUC'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model/kuairand_CPF/mlp_CPF.h5'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para['callback']['CPF_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 02:19:36.058715: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 02:19:36.059297: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 02:19:36.059641: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 02:19:36.060047: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 02:19:36.060388: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 02:19:36.060684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5092 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1431/1431 [==============================] - 41s 24ms/step - loss: 12.4389 - prototypes_61_auc: 0.5644 - prototypes_62_auc_1: 0.5746 - prototypes_63_auc_2: 0.5528 - prototypes_64_auc_3: 0.5760 - prototypes_65_auc_4: 0.4495 - val_loss: 11.3464 - val_prototypes_61_auc: 0.6066 - val_prototypes_62_auc_1: 0.6107 - val_prototypes_63_auc_2: 0.5843 - val_prototypes_64_auc_3: 0.6379 - val_prototypes_65_auc_4: 0.6060\n",
      "Epoch 2/50\n",
      "1431/1431 [==============================] - 24s 17ms/step - loss: 11.4522 - prototypes_61_auc: 0.5970 - prototypes_62_auc_1: 0.5888 - prototypes_63_auc_2: 0.5867 - prototypes_64_auc_3: 0.5918 - prototypes_65_auc_4: 0.5747 - val_loss: 10.9717 - val_prototypes_61_auc: 0.6106 - val_prototypes_62_auc_1: 0.6223 - val_prototypes_63_auc_2: 0.6409 - val_prototypes_64_auc_3: 0.6613 - val_prototypes_65_auc_4: 0.6887\n",
      "Epoch 3/50\n",
      "1431/1431 [==============================] - 25s 17ms/step - loss: 11.1378 - prototypes_61_auc: 0.6139 - prototypes_62_auc_1: 0.5913 - prototypes_63_auc_2: 0.6117 - prototypes_64_auc_3: 0.6112 - prototypes_65_auc_4: 0.6223 - val_loss: 10.7763 - val_prototypes_61_auc: 0.6488 - val_prototypes_62_auc_1: 0.6317 - val_prototypes_63_auc_2: 0.6681 - val_prototypes_64_auc_3: 0.6814 - val_prototypes_65_auc_4: 0.7084\n",
      "Epoch 4/50\n",
      "1431/1431 [==============================] - 23s 16ms/step - loss: 10.9469 - prototypes_61_auc: 0.6330 - prototypes_62_auc_1: 0.5948 - prototypes_63_auc_2: 0.6273 - prototypes_64_auc_3: 0.6280 - prototypes_65_auc_4: 0.6433 - val_loss: 10.6294 - val_prototypes_61_auc: 0.6715 - val_prototypes_62_auc_1: 0.6475 - val_prototypes_63_auc_2: 0.6876 - val_prototypes_64_auc_3: 0.7032 - val_prototypes_65_auc_4: 0.7192\n",
      "Epoch 5/50\n",
      "1431/1431 [==============================] - 24s 17ms/step - loss: 10.7985 - prototypes_61_auc: 0.6433 - prototypes_62_auc_1: 0.6082 - prototypes_63_auc_2: 0.6463 - prototypes_64_auc_3: 0.6490 - prototypes_65_auc_4: 0.6612 - val_loss: 10.4882 - val_prototypes_61_auc: 0.6882 - val_prototypes_62_auc_1: 0.6761 - val_prototypes_63_auc_2: 0.7195 - val_prototypes_64_auc_3: 0.7206 - val_prototypes_65_auc_4: 0.7343\n",
      "Epoch 6/50\n",
      "1431/1431 [==============================] - 24s 17ms/step - loss: 10.6632 - prototypes_61_auc: 0.6590 - prototypes_62_auc_1: 0.6350 - prototypes_63_auc_2: 0.6734 - prototypes_64_auc_3: 0.6734 - prototypes_65_auc_4: 0.6812 - val_loss: 10.3734 - val_prototypes_61_auc: 0.7135 - val_prototypes_62_auc_1: 0.7003 - val_prototypes_63_auc_2: 0.7401 - val_prototypes_64_auc_3: 0.7329 - val_prototypes_65_auc_4: 0.7462\n",
      "Epoch 7/50\n",
      "1431/1431 [==============================] - 23s 16ms/step - loss: 10.5575 - prototypes_61_auc: 0.6772 - prototypes_62_auc_1: 0.6582 - prototypes_63_auc_2: 0.6943 - prototypes_64_auc_3: 0.6912 - prototypes_65_auc_4: 0.6955 - val_loss: 10.3011 - val_prototypes_61_auc: 0.7262 - val_prototypes_62_auc_1: 0.7114 - val_prototypes_63_auc_2: 0.7465 - val_prototypes_64_auc_3: 0.7442 - val_prototypes_65_auc_4: 0.7493\n",
      "Epoch 8/50\n",
      "1431/1431 [==============================] - 24s 17ms/step - loss: 10.4822 - prototypes_61_auc: 0.6919 - prototypes_62_auc_1: 0.6721 - prototypes_63_auc_2: 0.7055 - prototypes_64_auc_3: 0.7030 - prototypes_65_auc_4: 0.7048 - val_loss: 10.2492 - val_prototypes_61_auc: 0.7408 - val_prototypes_62_auc_1: 0.7188 - val_prototypes_63_auc_2: 0.7499 - val_prototypes_64_auc_3: 0.7506 - val_prototypes_65_auc_4: 0.7526\n",
      "Epoch 9/50\n",
      "1431/1431 [==============================] - 24s 17ms/step - loss: 10.4239 - prototypes_61_auc: 0.7032 - prototypes_62_auc_1: 0.6823 - prototypes_63_auc_2: 0.7123 - prototypes_64_auc_3: 0.7128 - prototypes_65_auc_4: 0.7141 - val_loss: 10.2094 - val_prototypes_61_auc: 0.7464 - val_prototypes_62_auc_1: 0.7247 - val_prototypes_63_auc_2: 0.7520 - val_prototypes_64_auc_3: 0.7549 - val_prototypes_65_auc_4: 0.7561\n",
      "Epoch 10/50\n",
      "1431/1431 [==============================] - 24s 17ms/step - loss: 10.3729 - prototypes_61_auc: 0.7128 - prototypes_62_auc_1: 0.6923 - prototypes_63_auc_2: 0.7203 - prototypes_64_auc_3: 0.7202 - prototypes_65_auc_4: 0.7223 - val_loss: 10.1790 - val_prototypes_61_auc: 0.7493 - val_prototypes_62_auc_1: 0.7299 - val_prototypes_63_auc_2: 0.7541 - val_prototypes_64_auc_3: 0.7580 - val_prototypes_65_auc_4: 0.7599\n",
      "Epoch 11/50\n",
      "1431/1431 [==============================] - 24s 17ms/step - loss: 10.3353 - prototypes_61_auc: 0.7197 - prototypes_62_auc_1: 0.7000 - prototypes_63_auc_2: 0.7251 - prototypes_64_auc_3: 0.7257 - prototypes_65_auc_4: 0.7285 - val_loss: 10.1534 - val_prototypes_61_auc: 0.7522 - val_prototypes_62_auc_1: 0.7347 - val_prototypes_63_auc_2: 0.7561 - val_prototypes_64_auc_3: 0.7604 - val_prototypes_65_auc_4: 0.7636\n",
      "Epoch 12/50\n",
      "1431/1431 [==============================] - 25s 17ms/step - loss: 10.2998 - prototypes_61_auc: 0.7263 - prototypes_62_auc_1: 0.7071 - prototypes_63_auc_2: 0.7306 - prototypes_64_auc_3: 0.7323 - prototypes_65_auc_4: 0.7348 - val_loss: 10.1334 - val_prototypes_61_auc: 0.7546 - val_prototypes_62_auc_1: 0.7380 - val_prototypes_63_auc_2: 0.7581 - val_prototypes_64_auc_3: 0.7631 - val_prototypes_65_auc_4: 0.7674\n",
      "Epoch 13/50\n",
      "1431/1431 [==============================] - 24s 17ms/step - loss: 10.2722 - prototypes_61_auc: 0.7312 - prototypes_62_auc_1: 0.7132 - prototypes_63_auc_2: 0.7347 - prototypes_64_auc_3: 0.7375 - prototypes_65_auc_4: 0.7406 - val_loss: 10.1147 - val_prototypes_61_auc: 0.7569 - val_prototypes_62_auc_1: 0.7413 - val_prototypes_63_auc_2: 0.7605 - val_prototypes_64_auc_3: 0.7658 - val_prototypes_65_auc_4: 0.7711\n",
      "Epoch 14/50\n",
      "1431/1431 [==============================] - 22s 16ms/step - loss: 10.2448 - prototypes_61_auc: 0.7361 - prototypes_62_auc_1: 0.7200 - prototypes_63_auc_2: 0.7399 - prototypes_64_auc_3: 0.7428 - prototypes_65_auc_4: 0.7462 - val_loss: 10.0969 - val_prototypes_61_auc: 0.7595 - val_prototypes_62_auc_1: 0.7446 - val_prototypes_63_auc_2: 0.7634 - val_prototypes_64_auc_3: 0.7688 - val_prototypes_65_auc_4: 0.7748\n",
      "Epoch 15/50\n",
      "1431/1431 [==============================] - 22s 16ms/step - loss: 10.2179 - prototypes_61_auc: 0.7415 - prototypes_62_auc_1: 0.7260 - prototypes_63_auc_2: 0.7456 - prototypes_64_auc_3: 0.7486 - prototypes_65_auc_4: 0.7529 - val_loss: 10.0784 - val_prototypes_61_auc: 0.7625 - val_prototypes_62_auc_1: 0.7485 - val_prototypes_63_auc_2: 0.7665 - val_prototypes_64_auc_3: 0.7725 - val_prototypes_65_auc_4: 0.7788\n",
      "Epoch 16/50\n",
      "1431/1431 [==============================] - 23s 16ms/step - loss: 10.1908 - prototypes_61_auc: 0.7470 - prototypes_62_auc_1: 0.7325 - prototypes_63_auc_2: 0.7511 - prototypes_64_auc_3: 0.7549 - prototypes_65_auc_4: 0.7597 - val_loss: 10.0577 - val_prototypes_61_auc: 0.7664 - val_prototypes_62_auc_1: 0.7532 - val_prototypes_63_auc_2: 0.7708 - val_prototypes_64_auc_3: 0.7769 - val_prototypes_65_auc_4: 0.7835\n",
      "Epoch 17/50\n",
      "1431/1431 [==============================] - 22s 15ms/step - loss: 10.1609 - prototypes_61_auc: 0.7535 - prototypes_62_auc_1: 0.7405 - prototypes_63_auc_2: 0.7572 - prototypes_64_auc_3: 0.7623 - prototypes_65_auc_4: 0.7666 - val_loss: 10.0353 - val_prototypes_61_auc: 0.7708 - val_prototypes_62_auc_1: 0.7585 - val_prototypes_63_auc_2: 0.7753 - val_prototypes_64_auc_3: 0.7820 - val_prototypes_65_auc_4: 0.7887\n",
      "Epoch 18/50\n",
      "1431/1431 [==============================] - 21s 15ms/step - loss: 10.1279 - prototypes_61_auc: 0.7607 - prototypes_62_auc_1: 0.7485 - prototypes_63_auc_2: 0.7656 - prototypes_64_auc_3: 0.7701 - prototypes_65_auc_4: 0.7741 - val_loss: 10.0118 - val_prototypes_61_auc: 0.7756 - val_prototypes_62_auc_1: 0.7642 - val_prototypes_63_auc_2: 0.7802 - val_prototypes_64_auc_3: 0.7871 - val_prototypes_65_auc_4: 0.7939\n",
      "Epoch 19/50\n",
      "1431/1431 [==============================] - 23s 16ms/step - loss: 10.0950 - prototypes_61_auc: 0.7680 - prototypes_62_auc_1: 0.7571 - prototypes_63_auc_2: 0.7727 - prototypes_64_auc_3: 0.7781 - prototypes_65_auc_4: 0.7818 - val_loss: 9.9900 - val_prototypes_61_auc: 0.7798 - val_prototypes_62_auc_1: 0.7693 - val_prototypes_63_auc_2: 0.7843 - val_prototypes_64_auc_3: 0.7915 - val_prototypes_65_auc_4: 0.7986\n",
      "Epoch 20/50\n",
      "1431/1431 [==============================] - 21s 15ms/step - loss: 10.0626 - prototypes_61_auc: 0.7747 - prototypes_62_auc_1: 0.7650 - prototypes_63_auc_2: 0.7796 - prototypes_64_auc_3: 0.7858 - prototypes_65_auc_4: 0.7895 - val_loss: 9.9745 - val_prototypes_61_auc: 0.7833 - val_prototypes_62_auc_1: 0.7732 - val_prototypes_63_auc_2: 0.7876 - val_prototypes_64_auc_3: 0.7947 - val_prototypes_65_auc_4: 0.8022\n",
      "Epoch 21/50\n",
      "1431/1431 [==============================] - 21s 15ms/step - loss: 10.0355 - prototypes_61_auc: 0.7803 - prototypes_62_auc_1: 0.7718 - prototypes_63_auc_2: 0.7856 - prototypes_64_auc_3: 0.7912 - prototypes_65_auc_4: 0.7959 - val_loss: 9.9614 - val_prototypes_61_auc: 0.7857 - val_prototypes_62_auc_1: 0.7761 - val_prototypes_63_auc_2: 0.7897 - val_prototypes_64_auc_3: 0.7969 - val_prototypes_65_auc_4: 0.8048\n",
      "Epoch 22/50\n",
      "1431/1431 [==============================] - 21s 15ms/step - loss: 10.0107 - prototypes_61_auc: 0.7856 - prototypes_62_auc_1: 0.7772 - prototypes_63_auc_2: 0.7912 - prototypes_64_auc_3: 0.7964 - prototypes_65_auc_4: 0.8005 - val_loss: 9.9525 - val_prototypes_61_auc: 0.7877 - val_prototypes_62_auc_1: 0.7783 - val_prototypes_63_auc_2: 0.7915 - val_prototypes_64_auc_3: 0.7985 - val_prototypes_65_auc_4: 0.8066\n",
      "Epoch 23/50\n",
      "1431/1431 [==============================] - 20s 14ms/step - loss: 9.9894 - prototypes_61_auc: 0.7897 - prototypes_62_auc_1: 0.7825 - prototypes_63_auc_2: 0.7952 - prototypes_64_auc_3: 0.8008 - prototypes_65_auc_4: 0.8054 - val_loss: 9.9473 - val_prototypes_61_auc: 0.7889 - val_prototypes_62_auc_1: 0.7797 - val_prototypes_63_auc_2: 0.7923 - val_prototypes_64_auc_3: 0.7993 - val_prototypes_65_auc_4: 0.8077\n",
      "Epoch 24/50\n",
      "1431/1431 [==============================] - 21s 14ms/step - loss: 9.9742 - prototypes_61_auc: 0.7926 - prototypes_62_auc_1: 0.7858 - prototypes_63_auc_2: 0.7985 - prototypes_64_auc_3: 0.8039 - prototypes_65_auc_4: 0.8082 - val_loss: 9.9413 - val_prototypes_61_auc: 0.7898 - val_prototypes_62_auc_1: 0.7810 - val_prototypes_63_auc_2: 0.7932 - val_prototypes_64_auc_3: 0.8000 - val_prototypes_65_auc_4: 0.8085\n",
      "Epoch 25/50\n",
      "1431/1431 [==============================] - 20s 14ms/step - loss: 9.9589 - prototypes_61_auc: 0.7954 - prototypes_62_auc_1: 0.7890 - prototypes_63_auc_2: 0.8015 - prototypes_64_auc_3: 0.8069 - prototypes_65_auc_4: 0.8116 - val_loss: 9.9390 - val_prototypes_61_auc: 0.7908 - val_prototypes_62_auc_1: 0.7820 - val_prototypes_63_auc_2: 0.7943 - val_prototypes_64_auc_3: 0.8010 - val_prototypes_65_auc_4: 0.8094\n",
      "Epoch 26/50\n",
      "1431/1431 [==============================] - 21s 14ms/step - loss: 9.9460 - prototypes_61_auc: 0.7980 - prototypes_62_auc_1: 0.7918 - prototypes_63_auc_2: 0.8036 - prototypes_64_auc_3: 0.8097 - prototypes_65_auc_4: 0.8138 - val_loss: 9.9343 - val_prototypes_61_auc: 0.7913 - val_prototypes_62_auc_1: 0.7828 - val_prototypes_63_auc_2: 0.7947 - val_prototypes_64_auc_3: 0.8014 - val_prototypes_65_auc_4: 0.8099\n",
      "Epoch 27/50\n",
      "1431/1431 [==============================] - 20s 14ms/step - loss: 9.9351 - prototypes_61_auc: 0.8000 - prototypes_62_auc_1: 0.7939 - prototypes_63_auc_2: 0.8056 - prototypes_64_auc_3: 0.8115 - prototypes_65_auc_4: 0.8164 - val_loss: 9.9318 - val_prototypes_61_auc: 0.7918 - val_prototypes_62_auc_1: 0.7834 - val_prototypes_63_auc_2: 0.7951 - val_prototypes_64_auc_3: 0.8018 - val_prototypes_65_auc_4: 0.8105\n",
      "Epoch 28/50\n",
      "1431/1431 [==============================] - 21s 15ms/step - loss: 9.9250 - prototypes_61_auc: 0.8019 - prototypes_62_auc_1: 0.7960 - prototypes_63_auc_2: 0.8075 - prototypes_64_auc_3: 0.8135 - prototypes_65_auc_4: 0.8183 - val_loss: 9.9302 - val_prototypes_61_auc: 0.7922 - val_prototypes_62_auc_1: 0.7839 - val_prototypes_63_auc_2: 0.7955 - val_prototypes_64_auc_3: 0.8020 - val_prototypes_65_auc_4: 0.8108\n",
      "Epoch 29/50\n",
      "1431/1431 [==============================] - 21s 14ms/step - loss: 9.9149 - prototypes_61_auc: 0.8037 - prototypes_62_auc_1: 0.7982 - prototypes_63_auc_2: 0.8095 - prototypes_64_auc_3: 0.8156 - prototypes_65_auc_4: 0.8203 - val_loss: 9.9282 - val_prototypes_61_auc: 0.7927 - val_prototypes_62_auc_1: 0.7844 - val_prototypes_63_auc_2: 0.7960 - val_prototypes_64_auc_3: 0.8024 - val_prototypes_65_auc_4: 0.8112\n",
      "Epoch 30/50\n",
      "1431/1431 [==============================] - 21s 15ms/step - loss: 9.9067 - prototypes_61_auc: 0.8048 - prototypes_62_auc_1: 0.7998 - prototypes_63_auc_2: 0.8109 - prototypes_64_auc_3: 0.8168 - prototypes_65_auc_4: 0.8218 - val_loss: 9.9259 - val_prototypes_61_auc: 0.7929 - val_prototypes_62_auc_1: 0.7848 - val_prototypes_63_auc_2: 0.7963 - val_prototypes_64_auc_3: 0.8027 - val_prototypes_65_auc_4: 0.8114\n",
      "Epoch 31/50\n",
      "1431/1431 [==============================] - 21s 14ms/step - loss: 9.8986 - prototypes_61_auc: 0.8063 - prototypes_62_auc_1: 0.8014 - prototypes_63_auc_2: 0.8124 - prototypes_64_auc_3: 0.8182 - prototypes_65_auc_4: 0.8231 - val_loss: 9.9246 - val_prototypes_61_auc: 0.7930 - val_prototypes_62_auc_1: 0.7850 - val_prototypes_63_auc_2: 0.7965 - val_prototypes_64_auc_3: 0.8029 - val_prototypes_65_auc_4: 0.8116\n",
      "Epoch 32/50\n",
      "1431/1431 [==============================] - 20s 14ms/step - loss: 9.8921 - prototypes_61_auc: 0.8073 - prototypes_62_auc_1: 0.8027 - prototypes_63_auc_2: 0.8134 - prototypes_64_auc_3: 0.8195 - prototypes_65_auc_4: 0.8246 - val_loss: 9.9234 - val_prototypes_61_auc: 0.7935 - val_prototypes_62_auc_1: 0.7854 - val_prototypes_63_auc_2: 0.7968 - val_prototypes_64_auc_3: 0.8032 - val_prototypes_65_auc_4: 0.8119\n",
      "Epoch 33/50\n",
      "1431/1431 [==============================] - 22s 16ms/step - loss: 9.8849 - prototypes_61_auc: 0.8087 - prototypes_62_auc_1: 0.8040 - prototypes_63_auc_2: 0.8148 - prototypes_64_auc_3: 0.8209 - prototypes_65_auc_4: 0.8259 - val_loss: 9.9235 - val_prototypes_61_auc: 0.7936 - val_prototypes_62_auc_1: 0.7856 - val_prototypes_63_auc_2: 0.7971 - val_prototypes_64_auc_3: 0.8034 - val_prototypes_65_auc_4: 0.8120\n",
      "Epoch 34/50\n",
      "1431/1431 [==============================] - 23s 16ms/step - loss: 9.8792 - prototypes_61_auc: 0.8097 - prototypes_62_auc_1: 0.8055 - prototypes_63_auc_2: 0.8158 - prototypes_64_auc_3: 0.8215 - prototypes_65_auc_4: 0.8268 - val_loss: 9.9211 - val_prototypes_61_auc: 0.7936 - val_prototypes_62_auc_1: 0.7858 - val_prototypes_63_auc_2: 0.7973 - val_prototypes_64_auc_3: 0.8035 - val_prototypes_65_auc_4: 0.8120\n",
      "Epoch 35/50\n",
      "1431/1431 [==============================] - 22s 16ms/step - loss: 9.8745 - prototypes_61_auc: 0.8105 - prototypes_62_auc_1: 0.8060 - prototypes_63_auc_2: 0.8167 - prototypes_64_auc_3: 0.8223 - prototypes_65_auc_4: 0.8276 - val_loss: 9.9207 - val_prototypes_61_auc: 0.7938 - val_prototypes_62_auc_1: 0.7860 - val_prototypes_63_auc_2: 0.7974 - val_prototypes_64_auc_3: 0.8035 - val_prototypes_65_auc_4: 0.8122\n",
      "Epoch 36/50\n",
      "1431/1431 [==============================] - 23s 16ms/step - loss: 9.8673 - prototypes_61_auc: 0.8116 - prototypes_62_auc_1: 0.8072 - prototypes_63_auc_2: 0.8180 - prototypes_64_auc_3: 0.8237 - prototypes_65_auc_4: 0.8290 - val_loss: 9.9198 - val_prototypes_61_auc: 0.7940 - val_prototypes_62_auc_1: 0.7860 - val_prototypes_63_auc_2: 0.7975 - val_prototypes_64_auc_3: 0.8037 - val_prototypes_65_auc_4: 0.8123\n",
      "Epoch 37/50\n",
      "1431/1431 [==============================] - 22s 15ms/step - loss: 9.8633 - prototypes_61_auc: 0.8121 - prototypes_62_auc_1: 0.8081 - prototypes_63_auc_2: 0.8185 - prototypes_64_auc_3: 0.8247 - prototypes_65_auc_4: 0.8297 - val_loss: 9.9196 - val_prototypes_61_auc: 0.7941 - val_prototypes_62_auc_1: 0.7861 - val_prototypes_63_auc_2: 0.7977 - val_prototypes_64_auc_3: 0.8038 - val_prototypes_65_auc_4: 0.8124\n",
      "Epoch 38/50\n",
      "1431/1431 [==============================] - 22s 15ms/step - loss: 9.8585 - prototypes_61_auc: 0.8128 - prototypes_62_auc_1: 0.8089 - prototypes_63_auc_2: 0.8194 - prototypes_64_auc_3: 0.8254 - prototypes_65_auc_4: 0.8306 - val_loss: 9.9182 - val_prototypes_61_auc: 0.7940 - val_prototypes_62_auc_1: 0.7862 - val_prototypes_63_auc_2: 0.7977 - val_prototypes_64_auc_3: 0.8038 - val_prototypes_65_auc_4: 0.8124\n",
      "Epoch 39/50\n",
      "1431/1431 [==============================] - 23s 16ms/step - loss: 9.8558 - prototypes_61_auc: 0.8133 - prototypes_62_auc_1: 0.8093 - prototypes_63_auc_2: 0.8197 - prototypes_64_auc_3: 0.8258 - prototypes_65_auc_4: 0.8310 - val_loss: 9.9176 - val_prototypes_61_auc: 0.7944 - val_prototypes_62_auc_1: 0.7864 - val_prototypes_63_auc_2: 0.7980 - val_prototypes_64_auc_3: 0.8041 - val_prototypes_65_auc_4: 0.8125\n",
      "Epoch 40/50\n",
      "1431/1431 [==============================] - 23s 16ms/step - loss: 9.8514 - prototypes_61_auc: 0.8141 - prototypes_62_auc_1: 0.8101 - prototypes_63_auc_2: 0.8205 - prototypes_64_auc_3: 0.8264 - prototypes_65_auc_4: 0.8315 - val_loss: 9.9162 - val_prototypes_61_auc: 0.7943 - val_prototypes_62_auc_1: 0.7864 - val_prototypes_63_auc_2: 0.7981 - val_prototypes_64_auc_3: 0.8041 - val_prototypes_65_auc_4: 0.8126\n",
      "Epoch 41/50\n",
      "1431/1431 [==============================] - 23s 16ms/step - loss: 9.8476 - prototypes_61_auc: 0.8146 - prototypes_62_auc_1: 0.8107 - prototypes_63_auc_2: 0.8211 - prototypes_64_auc_3: 0.8272 - prototypes_65_auc_4: 0.8323 - val_loss: 9.9163 - val_prototypes_61_auc: 0.7945 - val_prototypes_62_auc_1: 0.7865 - val_prototypes_63_auc_2: 0.7982 - val_prototypes_64_auc_3: 0.8042 - val_prototypes_65_auc_4: 0.8125\n",
      "Epoch 42/50\n",
      "1431/1431 [==============================] - 22s 15ms/step - loss: 9.8429 - prototypes_61_auc: 0.8153 - prototypes_62_auc_1: 0.8116 - prototypes_63_auc_2: 0.8218 - prototypes_64_auc_3: 0.8278 - prototypes_65_auc_4: 0.8331 - val_loss: 9.9156 - val_prototypes_61_auc: 0.7945 - val_prototypes_62_auc_1: 0.7865 - val_prototypes_63_auc_2: 0.7982 - val_prototypes_64_auc_3: 0.8042 - val_prototypes_65_auc_4: 0.8125\n",
      "Epoch 43/50\n",
      "1431/1431 [==============================] - 24s 17ms/step - loss: 9.8404 - prototypes_61_auc: 0.8157 - prototypes_62_auc_1: 0.8120 - prototypes_63_auc_2: 0.8223 - prototypes_64_auc_3: 0.8281 - prototypes_65_auc_4: 0.8332 - val_loss: 9.9155 - val_prototypes_61_auc: 0.7945 - val_prototypes_62_auc_1: 0.7864 - val_prototypes_63_auc_2: 0.7981 - val_prototypes_64_auc_3: 0.8041 - val_prototypes_65_auc_4: 0.8125\n",
      "Epoch 44/50\n",
      "1431/1431 [==============================] - 24s 17ms/step - loss: 9.8370 - prototypes_61_auc: 0.8162 - prototypes_62_auc_1: 0.8125 - prototypes_63_auc_2: 0.8228 - prototypes_64_auc_3: 0.8289 - prototypes_65_auc_4: 0.8339 - val_loss: 9.9155 - val_prototypes_61_auc: 0.7945 - val_prototypes_62_auc_1: 0.7864 - val_prototypes_63_auc_2: 0.7982 - val_prototypes_64_auc_3: 0.8042 - val_prototypes_65_auc_4: 0.8125\n",
      "Epoch 45/50\n",
      "1431/1431 [==============================] - 22s 16ms/step - loss: 9.8337 - prototypes_61_auc: 0.8167 - prototypes_62_auc_1: 0.8132 - prototypes_63_auc_2: 0.8234 - prototypes_64_auc_3: 0.8292 - prototypes_65_auc_4: 0.8346 - val_loss: 9.9157 - val_prototypes_61_auc: 0.7945 - val_prototypes_62_auc_1: 0.7864 - val_prototypes_63_auc_2: 0.7982 - val_prototypes_64_auc_3: 0.8041 - val_prototypes_65_auc_4: 0.8125\n",
      "Epoch 46/50\n",
      "1431/1431 [==============================] - 19s 14ms/step - loss: 9.8305 - prototypes_61_auc: 0.8172 - prototypes_62_auc_1: 0.8135 - prototypes_63_auc_2: 0.8237 - prototypes_64_auc_3: 0.8299 - prototypes_65_auc_4: 0.8351 - val_loss: 9.9153 - val_prototypes_61_auc: 0.7945 - val_prototypes_62_auc_1: 0.7864 - val_prototypes_63_auc_2: 0.7982 - val_prototypes_64_auc_3: 0.8041 - val_prototypes_65_auc_4: 0.8125\n",
      "Epoch 47/50\n",
      "1431/1431 [==============================] - 22s 15ms/step - loss: 9.8274 - prototypes_61_auc: 0.8176 - prototypes_62_auc_1: 0.8141 - prototypes_63_auc_2: 0.8242 - prototypes_64_auc_3: 0.8301 - prototypes_65_auc_4: 0.8355 - val_loss: 9.9141 - val_prototypes_61_auc: 0.7944 - val_prototypes_62_auc_1: 0.7863 - val_prototypes_63_auc_2: 0.7982 - val_prototypes_64_auc_3: 0.8041 - val_prototypes_65_auc_4: 0.8126\n",
      "Epoch 48/50\n",
      "1431/1431 [==============================] - 22s 15ms/step - loss: 9.8262 - prototypes_61_auc: 0.8178 - prototypes_62_auc_1: 0.8143 - prototypes_63_auc_2: 0.8245 - prototypes_64_auc_3: 0.8302 - prototypes_65_auc_4: 0.8357 - val_loss: 9.9152 - val_prototypes_61_auc: 0.7946 - val_prototypes_62_auc_1: 0.7864 - val_prototypes_63_auc_2: 0.7983 - val_prototypes_64_auc_3: 0.8043 - val_prototypes_65_auc_4: 0.8127\n",
      "Epoch 49/50\n",
      "1431/1431 [==============================] - 21s 15ms/step - loss: 9.8222 - prototypes_61_auc: 0.8183 - prototypes_62_auc_1: 0.8150 - prototypes_63_auc_2: 0.8250 - prototypes_64_auc_3: 0.8309 - prototypes_65_auc_4: 0.8364 - val_loss: 9.9155 - val_prototypes_61_auc: 0.7943 - val_prototypes_62_auc_1: 0.7861 - val_prototypes_63_auc_2: 0.7980 - val_prototypes_64_auc_3: 0.8040 - val_prototypes_65_auc_4: 0.8124\n",
      "Epoch 50/50\n",
      "1431/1431 [==============================] - 22s 15ms/step - loss: 9.8200 - prototypes_61_auc: 0.8186 - prototypes_62_auc_1: 0.8152 - prototypes_63_auc_2: 0.8253 - prototypes_64_auc_3: 0.8313 - prototypes_65_auc_4: 0.8369 - val_loss: 9.9147 - val_prototypes_61_auc: 0.7946 - val_prototypes_62_auc_1: 0.7863 - val_prototypes_63_auc_2: 0.7981 - val_prototypes_64_auc_3: 0.8040 - val_prototypes_65_auc_4: 0.8124\n"
     ]
    }
   ],
   "source": [
    "seed_tensorflow(seed=para['seed'])\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_output_5_loss',  \n",
    "    mode='min',          \n",
    "    patience=para['callback']['patience'] \n",
    ")\n",
    "checkpoint_auc = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=para['callback']['CPF_model'],  # 保存模型的路径\n",
    "    monitor='val_output_5_auc',  # 监控验证集 AUC\n",
    "    mode='max',          # 保存验证 AUC 最大的模型\n",
    "    save_weights_only=True,  # 只保存模型权重\n",
    "    save_best_only=True  # 只保存最佳模型\n",
    ")\n",
    "hist = model.fit(X_train,\n",
    "                 y_train,\n",
    "                 epochs=50,\n",
    "                 batch_size=512,\n",
    "                 shuffle=True,\n",
    "                 verbose=para['verbose'],\n",
    "                 callbacks=[checkpoint_auc,es_callback],\n",
    "                 validation_data=(X_valid,y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 02:54:58.356403: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 02:54:58.357128: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 02:54:58.357400: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 02:54:58.357722: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 02:54:58.357932: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-23 02:54:58.358049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5092 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "seed_tensorflow(seed=para['seed'])\n",
    "model.load_weights(para['callback']['CPF_model'])\n",
    "y_test_pred = model.predict(X_test,batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP\n",
      "auc: 0.78749484\n",
      "logloss: 0.5131945\n"
     ]
    }
   ],
   "source": [
    "print(\"SP\")\n",
    "auc_metric = tf.keras.metrics.AUC()\n",
    "auc_metric.update_state(y_test[0], y_test_pred[0])\n",
    "auc = auc_metric.result().numpy()\n",
    "\n",
    "logloss_metric = tf.keras.metrics.BinaryCrossentropy()\n",
    "\n",
    "logloss_metric.update_state(y_test[0], y_test_pred[0])\n",
    "log_loss = logloss_metric.result().numpy()\n",
    "print('auc:',auc)\n",
    "print('logloss:',log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP\n",
      "auc: 0.77822256\n",
      "logloss: 0.4901078\n"
     ]
    }
   ],
   "source": [
    "print(\"BP\")\n",
    "auc_metric = tf.keras.metrics.AUC()\n",
    "auc_metric.update_state(y_test[1], y_test_pred[1])\n",
    "auc = auc_metric.result().numpy()\n",
    "\n",
    "logloss_metric = tf.keras.metrics.BinaryCrossentropy()\n",
    "\n",
    "logloss_metric.update_state(y_test[1], y_test_pred[1])\n",
    "log_loss = logloss_metric.result().numpy()\n",
    "print('auc:',auc)\n",
    "print('logloss:',log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP\n",
      "auc: 0.79135776\n",
      "logloss: 0.468202\n"
     ]
    }
   ],
   "source": [
    "print(\"EP\")\n",
    "auc_metric = tf.keras.metrics.AUC()\n",
    "auc_metric.update_state(y_test[2], y_test_pred[2])\n",
    "auc = auc_metric.result().numpy()\n",
    "\n",
    "logloss_metric = tf.keras.metrics.BinaryCrossentropy()\n",
    "\n",
    "logloss_metric.update_state(y_test[2], y_test_pred[2])\n",
    "log_loss = logloss_metric.result().numpy()\n",
    "print('auc:',auc)\n",
    "print('logloss:',log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LP\n",
      "auc: 0.7979415\n",
      "logloss: 0.38339123\n"
     ]
    }
   ],
   "source": [
    "print(\"LP\")\n",
    "auc_metric = tf.keras.metrics.AUC()\n",
    "auc_metric.update_state(y_test[3], y_test_pred[3])\n",
    "auc = auc_metric.result().numpy()\n",
    "\n",
    "logloss_metric = tf.keras.metrics.BinaryCrossentropy()\n",
    "\n",
    "logloss_metric.update_state(y_test[3], y_test_pred[3])\n",
    "log_loss = logloss_metric.result().numpy()\n",
    "print('auc:',auc)\n",
    "print('logloss:',log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CP\n",
      "auc: 0.81331967\n",
      "logloss: 0.32460374\n"
     ]
    }
   ],
   "source": [
    "print(\"CP\")\n",
    "auc_metric = tf.keras.metrics.AUC()\n",
    "auc_metric.update_state(y_test[4], y_test_pred[4])\n",
    "auc = auc_metric.result().numpy()\n",
    "\n",
    "logloss_metric = tf.keras.metrics.BinaryCrossentropy()\n",
    "\n",
    "logloss_metric.update_state(y_test[4], y_test_pred[4])\n",
    "log_loss = logloss_metric.result().numpy()\n",
    "print('auc:',auc)\n",
    "print('logloss:',log_loss)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf215",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
